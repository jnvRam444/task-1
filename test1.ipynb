{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1: Chat with PDF Using RAG Pipeline<br>\n",
        "**Overview** <br>\n",
        "The goal is to implement a Retrieval-Augmented Generation (RAG) pipeline\n",
        "   that allows users to\n",
        "interact with semi-structured data in multiple PDF files. The system should extract, chunk,\n",
        "embed, and store the data for eficient retrieval. It will answer user queries and perform\n",
        "comparisons accurately, leveraging the selected LLM model for generating responses.<br>\n",
        "**Functional Requirements** <br>\n",
        "**1. Data Ingestion**\n",
        "• Input: PDF files containing semi-structured data.\n",
        "• Process:\n",
        "o Extract text and relevant structured information from PDF files.\n",
        "o Segment data into logical chunks for better granularity.\n",
        "o Convert chunks into vector embeddings using a pre-trained embedding model.\n",
        "o Store embeddings in a vector database for e icient similarity-based retrieval. <br>\n",
        "**2. Query Handling**\n",
        "• Input: User's natural language question.\n",
        "• Process:\n",
        "o Convert the user's query into vector embeddings using the same embedding\n",
        "model.\n",
        "o Perform a similarity search in the vector database to retrieve the most relevant\n",
        "chunks.\n",
        "o Pass the retrieved chunks to the LLM along with a prompt or agentic context to\n",
        "generate a detailed response.<br>\n",
        "**3. Comparison Queries**\n",
        "• Input: User's query asking for a comparison  \n",
        "• Process:\n",
        "o Identify and extract the relevant terms or fields to compare across multiple PDF\n",
        "f\n",
        " iles.\n",
        "o Retrieve the corresponding chunks from the vector database.\n",
        "o Process and aggregate data for comparison.\n",
        "o Generate a structured response (e.g., tabular or bullet-point format).<br>\n",
        "**4. Response Generation**\n",
        "• Input: Relevant information retrieved from the vector database and the user query.\n",
        "• Process:\n",
        "o Use the LLM with retrieval-augmented prompts to produce responses with exact\n",
        "values and context.\n",
        "o Ensure factuality by incorporating retrieved data directly into the response."
      ],
      "metadata": {
        "id": "9mvp6ZoOYC_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyMuPDF transformers sentence-transformers faiss-cpu openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aHugb-_MaSdo",
        "outputId": "93f940ee-c888-46c0-b284-b8c33f319132"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.11.10)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.18.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF, faiss-cpu\n",
            "Successfully installed PyMuPDF-1.25.1 faiss-cpu-1.9.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuCV4eEGX_GS",
        "outputId": "4903be9a-5d85-4c3b-bb1f-67057878520f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your query: from page 2 get exact unempoyment information based on type of degree input\n",
            "Response:  It appears that the content you provided doesn’t explicitly include any data or information regarding unemployment rates based on different types of degrees. If this information was contained in a specific table or section not included in your message, please share that portion directly so I can assist you better.\n",
            "\n",
            "If you want to know about typical unemployment rates by degree type, I can provide general knowledge in that area. Generally, higher education levels tend to correlate with lower unemployment rates. Would you like to know more about that or provide specific data for analysis?\n"
          ]
        }
      ],
      "source": [
        "import fitz  # PyMuPDF for PDF extraction\n",
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import openai\n",
        "\n",
        "# Step 1: Extract Text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# Step 2: Text Chunking\n",
        "def chunk_text(text, chunk_size=500):\n",
        "    # Split text into smaller chunks for processing\n",
        "    chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "    return chunks\n",
        "\n",
        "# Step 3: Embed Text using Sentence-Transformers (or OpenAI)\n",
        "def embed_text(chunks, model_name=\"all-MiniLM-L6-v2\"):\n",
        "    model = SentenceTransformer(model_name)\n",
        "    embeddings = model.encode(chunks, convert_to_tensor=True)\n",
        "    return embeddings\n",
        "\n",
        "# Step 4: Store Embeddings in FAISS (for efficient retrieval)\n",
        "def create_faiss_index(embeddings):\n",
        "    dim = embeddings.shape[1]  # Dimension of the embeddings\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    faiss.normalize_L2(embeddings)  # Optional: Normalize the vectors\n",
        "    index.add(embeddings)  # Add the embeddings to the index\n",
        "    return index\n",
        "\n",
        "# Step 5: Perform Retrieval and Response Generation\n",
        "def retrieve_relevant_chunks(query, index, chunks, model_name=\"all-MiniLM-L6-v2\"):\n",
        "    # Embed the query\n",
        "    model = SentenceTransformer(model_name)\n",
        "    query_embedding = model.encode([query], convert_to_tensor=True)\n",
        "\n",
        "    # Search in FAISS\n",
        "    D, I = index.search(query_embedding, k=5)  # Retrieve top 5 relevant chunks\n",
        "    relevant_chunks = [chunks[i] for i in I[0]]\n",
        "    return relevant_chunks\n",
        "\n",
        "def generate_response(query, relevant_chunks):\n",
        "    context = \"\\n\".join(relevant_chunks)\n",
        "    # Use OpenAI or any LLM model to generate a response based on the context\n",
        "    openai.api_key = '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'\n",
        "    # Use openai.ChatCompletion.create for chat models like gpt-4o-mini\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Answer the following question based on the context:\\n\\n{context}\\n\\nQuestion: {query}\"}\n",
        "        ],\n",
        "        max_tokens=300\n",
        "    )\n",
        "    return response.choices[0].message.content.strip() # Access the message content\n",
        "# Example Usage\n",
        "def rag_pipeline(pdf_path, query):\n",
        "    all_chunks = []\n",
        "    all_embeddings = []\n",
        "\n",
        "    # Extract text from the PDF and chunk it\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    chunks = chunk_text(text)\n",
        "    all_chunks.extend(chunks)\n",
        "\n",
        "    # Embed the chunks and store in FAISS index\n",
        "    embeddings = embed_text(all_chunks)\n",
        "    index = create_faiss_index(embeddings.numpy())\n",
        "\n",
        "    # Retrieve relevant chunks for the query\n",
        "    relevant_chunks = retrieve_relevant_chunks(query, index, all_chunks)\n",
        "\n",
        "    # Generate and return the response\n",
        "    response = generate_response(query, relevant_chunks)\n",
        "    return response\n",
        "\n",
        "# Main function to get user input and run the RAG pipeline\n",
        "# Get the query from the user\n",
        "query = input(\"Please enter your query: \")\n",
        "\n",
        "# Specify the path of the PDF file you want to process\n",
        "pdf_path = \"/content/test1.pdf\"\n",
        "# Replace with your actual PDF path\n",
        "\n",
        "# Run the RAG pipeline and get the response\n",
        "response = rag_pipeline(pdf_path, query)\n",
        "print(\"Response: \", response)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rD7xOUTwc7c_",
        "outputId": "32a22dc2-59c5-4a96-8ba9-3e23d9312760"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.12.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.57.4\n",
            "    Uninstalling openai-1.57.4:\n",
            "      Successfully uninstalled openai-1.57.4\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    }
  ]
}
